{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4130910,"sourceType":"datasetVersion","datasetId":2440665}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, average_precision_score\nfrom sklearn.preprocessing import label_binarize\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0, ResNet50, DenseNet121, MobileNet, MobileNetV2\nfrom tensorflow.keras.optimizers import AdamW\nimport math\nimport itertools\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, average_precision_score\nfrom sklearn.preprocessing import label_binarize\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0, ResNet50, DenseNet121, MobileNet, MobileNetV2,VGG16\nfrom tensorflow.keras.optimizers import AdamW\nimport math\nimport itertools\n\ndata_dir = r\"/kaggle/input/eye-diseases-classification/dataset\"\nfilepaths = []\nlabels = []\nfolds = os.listdir(data_dir)\nfor fold in folds:\n    foldpath = os.path.join(data_dir, fold)\n    filelist = os.listdir(foldpath)\n    for file in filelist:\n        fpath = os.path.join(foldpath, file)\n        filepaths.append(fpath)\n        labels.append(fold)\n\nFseries = pd.Series(filepaths, name='filepaths')\nLseries = pd.Series(labels, name='labels')\ndf = pd.concat([Fseries, Lseries], axis=1)\n\n\nprint(\"Class distribution:\")\nprint(df['labels'].value_counts())\nprint(f\"Number of unique classes: {df['labels'].nunique()}\")\n\n# Split data\ntrain_df, dummy_df = train_test_split(df, train_size=0.8, shuffle=True, random_state=42)\nvalid_df, test_df = train_test_split(dummy_df, train_size=0.6, shuffle=True, random_state=42)\n\nprint(f\"Train samples: {len(train_df)}\")\nprint(f\"Valid samples: {len(valid_df)}\")\nprint(f\"Test samples: {len(test_df)}\")\n\n# Create data generators\nbatch_size = 32\nimg_size = (224, 224)\nchannels = 3\n\ntr_gen = ImageDataGenerator(rescale=1./255)\nts_gen = ImageDataGenerator(rescale=1./255)\n\ntrain_gen = tr_gen.flow_from_dataframe(\n    train_df, x_col='filepaths', y_col='labels', \n    target_size=img_size, class_mode='categorical',\n    color_mode='rgb', shuffle=True, batch_size=batch_size\n)\nvalid_gen = ts_gen.flow_from_dataframe(\n    valid_df, x_col='filepaths', y_col='labels', \n    target_size=img_size, class_mode='categorical',\n    color_mode='rgb', shuffle=True, batch_size=batch_size\n)\ntest_gen = ts_gen.flow_from_dataframe(\n    test_df, x_col='filepaths', y_col='labels', \n    target_size=img_size, class_mode='categorical',\n    color_mode='rgb', shuffle=False, batch_size=batch_size\n)\n\n# Get number of classes\nnum_classes = 4\nclass_names = list(train_gen.class_indices.keys())\nprint(f\"Classes: {class_names}\")\n\n# ViT Small Implementation\nclass PatchEmbedding(layers.Layer):\n    def __init__(self, patch_size=16, embed_dim=384):\n        super().__init__()\n        self.patch_size = patch_size\n        self.embed_dim = embed_dim\n        self.projection = layers.Conv2D(\n            embed_dim, kernel_size=patch_size, strides=patch_size, padding='valid'\n        )\n        \n    def call(self, x):\n        # x shape: (batch_size, height, width, channels)\n        batch_size = tf.shape(x)[0]\n        patches = self.projection(x)  # (batch_size, num_patches_h, num_patches_w, embed_dim)\n        patches = tf.reshape(patches, [batch_size, -1, self.embed_dim])\n        return patches\n\nclass MultiHeadAttention(layers.Layer):\n    def __init__(self, embed_dim, num_heads):\n        super().__init__()\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.head_dim = embed_dim // num_heads\n        \n        self.qkv = layers.Dense(embed_dim * 3)\n        self.projection = layers.Dense(embed_dim)\n        \n    def call(self, x):\n        batch_size, seq_len, embed_dim = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2]\n        \n        # Generate Q, K, V\n        qkv = self.qkv(x)  # (batch_size, seq_len, embed_dim * 3)\n        qkv = tf.reshape(qkv, [batch_size, seq_len, 3, self.num_heads, self.head_dim])\n        qkv = tf.transpose(qkv, [2, 0, 3, 1, 4])  # (3, batch_size, num_heads, seq_len, head_dim)\n        q, k, v = qkv[0], qkv[1], qkv[2]\n        \n        # Attention\n        scale = tf.cast(self.head_dim, tf.float32) ** -0.5\n        attn = tf.matmul(q, k, transpose_b=True) * scale\n        attn = tf.nn.softmax(attn, axis=-1)\n        \n        out = tf.matmul(attn, v)\n        out = tf.transpose(out, [0, 2, 1, 3])  # (batch_size, seq_len, num_heads, head_dim)\n        out = tf.reshape(out, [batch_size, seq_len, embed_dim])\n        \n        return self.projection(out)\n\nclass TransformerBlock(layers.Layer):\n    def __init__(self, embed_dim, num_heads, mlp_ratio=4.0, dropout=0.1):\n        super().__init__()\n        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n        self.attn = MultiHeadAttention(embed_dim, num_heads)\n        self.dropout1 = layers.Dropout(dropout)\n        \n        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n        mlp_hidden_dim = int(embed_dim * mlp_ratio)\n        self.mlp = keras.Sequential([\n            layers.Dense(mlp_hidden_dim, activation='gelu'),\n            layers.Dropout(dropout),\n            layers.Dense(embed_dim),\n            layers.Dropout(dropout)\n        ])\n        \n    def call(self, x, training=None):\n        # Self attention\n        attn_out = self.attn(self.norm1(x))\n        x = x + self.dropout1(attn_out, training=training)\n        \n        # MLP\n        mlp_out = self.mlp(self.norm2(x), training=training)\n        x = x + mlp_out\n        \n        return x\n\nclass VisionTransformerSmall(keras.Model):\n    def __init__(self, \n                 img_size=224,\n                 patch_size=16, \n                 num_classes=4,\n                 embed_dim=384,\n                 depth=12,\n                 num_heads=6,\n                 mlp_ratio=4.0,\n                 dropout=0.1):\n        super().__init__()\n        \n        self.img_size = img_size\n        self.patch_size = patch_size\n        self.num_patches = (img_size // patch_size) ** 2\n        \n        # Patch embedding\n        self.patch_embed = PatchEmbedding(patch_size, embed_dim)\n        \n        # Class token and position embedding\n        self.class_token = self.add_weight(\n            shape=(1, 1, embed_dim),\n            initializer='random_normal',\n            trainable=True,\n            name='class_token'\n        )\n        \n        self.pos_embed = self.add_weight(\n            shape=(1, self.num_patches + 1, embed_dim),\n            initializer='random_normal',\n            trainable=True,\n            name='pos_embed'\n        )\n        \n        self.dropout = layers.Dropout(dropout)\n        \n        # Transformer blocks\n        self.blocks = [\n            TransformerBlock(embed_dim, num_heads, mlp_ratio, dropout)\n            for _ in range(depth)\n        ]\n        \n        self.norm = layers.LayerNormalization(epsilon=1e-6)\n        self.head = layers.Dense(num_classes)\n        \n    def call(self, x, training=None):\n        batch_size = tf.shape(x)[0]\n        \n        # Patch embedding\n        x = self.patch_embed(x)  # (batch_size, num_patches, embed_dim)\n        \n        # Add class token\n        class_tokens = tf.broadcast_to(self.class_token, [batch_size, 1, tf.shape(self.class_token)[-1]])\n        x = tf.concat([class_tokens, x], axis=1)\n        \n        # Add position embedding\n        x = x + self.pos_embed\n        x = self.dropout(x, training=training)\n        \n        # Transformer blocks\n        for block in self.blocks:\n            x = block(x, training=training)\n            \n        x = self.norm(x)\n        \n        # Classification head (use class token)\n        class_token_final = x[:, 0]\n        return self.head(class_token_final)\n\n# Create ViT Small model\ndef create_vit_small(num_classes):\n    return VisionTransformerSmall(\n        img_size=224,\n        patch_size=16,\n        num_classes=num_classes,\n        embed_dim=384,\n        depth=12,\n        num_heads=6,\n        mlp_ratio=4.0,\n        dropout=0.1\n    )\n\n# Create comparison models\ndef create_efficientnet(num_classes):\n    base_model = EfficientNetB0(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(224, 224, 3)\n    )\n    \n    model = keras.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dropout(0.2),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    return model\n\ndef create_resnet50(num_classes):\n    base_model = ResNet50(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(224, 224, 3)\n    )\n    \n    model = keras.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dropout(0.2),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    return model\n\ndef create_densenet121(num_classes):\n    base_model = DenseNet121(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(224, 224, 3)\n    )\n    \n    model = keras.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dropout(0.2),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    return model\ndef create_VGG(num_classes):\n    base_model=VGG16(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(224,224,3)\n    )\n    model = keras.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dropout(0.2),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    return model\ndef create_mobilenet_v1(num_classes):\n    base_model = MobileNet(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(224, 224, 3)\n    )\n    \n    model = keras.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dropout(0.2),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    return model\n\ndef create_mobilenet_v2(num_classes):\n    base_model = MobileNetV2(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(224, 224, 3)\n    )\n    \n    model = keras.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dropout(0.2),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    return model\n\n# Enhanced training history visualization function\ndef plot_clean_training_history(history, model_name):\n    tr_acc = history.history['accuracy']\n    tr_loss = history.history['loss']\n    val_acc = history.history['val_accuracy']\n    val_loss = history.history['val_loss']\n    \n    # Find best epochs\n    index_loss = np.argmin(val_loss)\n    val_lowest = val_loss[index_loss]\n    index_acc = np.argmax(val_acc)\n    acc_highest = val_acc[index_acc]\n    \n    Epochs = [i+1 for i in range(len(tr_acc))]\n    loss_label = f'best epoch= {str(index_loss + 1)}'\n    acc_label = f'best epoch= {str(index_acc + 1)}'\n    \n    # Plot training history\n    plt.figure(figsize=(15, 8))\n    plt.style.use('fivethirtyeight')\n    \n    # Loss plot\n    plt.subplot(1, 2, 1)\n    plt.plot(Epochs, tr_loss, label='Training loss', linewidth=2)\n    plt.plot(Epochs, val_loss, label='Validation loss', linewidth=2)\n    plt.scatter(index_loss + 1, val_lowest, s=150, c='blue', label=loss_label, zorder=5)\n    plt.title(f'{model_name} - Training and Validation Loss', fontsize=14, fontweight='bold')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    # Accuracy plot\n    plt.subplot(1, 2, 2)\n    plt.plot(Epochs, tr_acc, 'r', label='Training Accuracy', linewidth=2)\n    plt.plot(Epochs, val_acc, 'g', label='Validation Accuracy', linewidth=2)\n    plt.scatter(index_acc + 1, acc_highest, s=150, c='blue', label=acc_label, zorder=5)\n    plt.title(f'{model_name} - Training and Validation Accuracy', fontsize=14, fontweight='bold')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Print best epoch information\n    print(f\"\\n{model_name} Training Summary:\")\n    print(f\"  Best Validation Loss: {val_lowest:.4f} at epoch {index_loss + 1}\")\n    print(f\"  Best Validation Accuracy: {acc_highest:.4f} at epoch {index_acc + 1}\")\n    print(f\"  Final Training Accuracy: {tr_acc[-1]:.4f}\")\n    print(f\"  Final Validation Accuracy: {val_acc[-1]:.4f}\")\n    print(f\"  Overfitting (Train-Val): {tr_acc[-1] - val_acc[-1]:.4f}\")\n\n# Combined training history visualization for all models\ndef plot_combined_clean_histories(histories):\n   \n    plt.figure(figsize=(20, 12))\n    plt.style.use('fivethirtyeight')\n    \n    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57', '#FF9FF3']\n    \n    # Training Loss\n    plt.subplot(2, 2, 1)\n    for idx, (model_name, history) in enumerate(histories.items()):\n        epochs = [i+1 for i in range(len(history.history['loss']))]\n        plt.plot(epochs, history.history['loss'], \n                color=colors[idx % len(colors)], linewidth=2, label=model_name)\n    plt.title('Training Loss Comparison', fontsize=16, fontweight='bold')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    # Validation Loss\n    plt.subplot(2, 2, 2)\n    for idx, (model_name, history) in enumerate(histories.items()):\n        epochs = [i+1 for i in range(len(history.history['val_loss']))]\n        val_loss = history.history['val_loss']\n        plt.plot(epochs, val_loss, \n                color=colors[idx % len(colors)], linewidth=2, label=model_name)\n        \n        # Mark best epoch\n        best_epoch = np.argmin(val_loss) + 1\n        best_loss = min(val_loss)\n        plt.scatter(best_epoch, best_loss, \n                   color=colors[idx % len(colors)], s=100, zorder=5)\n        \n    plt.title('Validation Loss Comparison', fontsize=16, fontweight='bold')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    # Training Accuracy\n    plt.subplot(2, 2, 3)\n    for idx, (model_name, history) in enumerate(histories.items()):\n        epochs = [i+1 for i in range(len(history.history['accuracy']))]\n        plt.plot(epochs, history.history['accuracy'], \n                color=colors[idx % len(colors)], linewidth=2, label=model_name)\n    plt.title('Training Accuracy Comparison', fontsize=16, fontweight='bold')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    # Validation Accuracy\n    plt.subplot(2, 2, 4)\n    for idx, (model_name, history) in enumerate(histories.items()):\n        epochs = [i+1 for i in range(len(history.history['val_accuracy']))]\n        val_acc = history.history['val_accuracy']\n        plt.plot(epochs, val_acc, \n                color=colors[idx % len(colors)], linewidth=2, label=model_name)\n        \n        # Mark best epoch\n        best_epoch = np.argmax(val_acc) + 1\n        best_acc = max(val_acc)\n        plt.scatter(best_epoch, best_acc, \n                   color=colors[idx % len(colors)], s=100, zorder=5)\n        \n    plt.title('Validation Accuracy Comparison', fontsize=16, fontweight='bold')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n\n# Model compilation and training function\ndef compile_and_train_model(model, model_name, train_gen, valid_gen, epochs=50):\n    print(f\"\\n{'='*50}\")\n    print(f\"Training {model_name}\")\n    print(f\"{'='*50}\")\n    \n    # Learning rate schedule\n    initial_lr = 1e-3 if 'ViT' in model_name else 1e-4\n    total_steps = len(train_gen) * epochs\n    lr_schedule = keras.optimizers.schedules.CosineDecay(\n        initial_learning_rate=initial_lr,\n        decay_steps=total_steps,\n        alpha=0.1\n    )\n    \n    # Compile model\n    optimizer = AdamW(learning_rate=lr_schedule, weight_decay=1e-4) if 'ViT' in model_name else keras.optimizers.Adam(learning_rate=lr_schedule)\n    \n    model.compile(\n        optimizer=optimizer,\n        loss='categorical_crossentropy',\n        metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')]\n    )\n    \n    # Train model\n    history = model.fit(\n        train_gen,\n        validation_data=valid_gen,\n        epochs=40,\n        verbose=1\n    )\n    \n    # Plot individual training history with clean visualization\n    plot_clean_training_history(history, model_name)\n    \n    return model, history\n\n# Inference time measurement\ndef measure_inference_time(model, test_gen, num_batches=10):\n    times = []\n    \n    for i, (x_batch, y_batch) in enumerate(test_gen):\n        if i >= num_batches:\n            break\n        \n        start_time = time.time()\n        _ = model.predict(x_batch, verbose=0)\n        end_time = time.time()\n        \n        times.append(end_time - start_time)\n    \n    avg_time_per_batch = np.mean(times)\n    avg_time_per_image = avg_time_per_batch / batch_size\n    \n    return avg_time_per_batch, avg_time_per_image\n\n# Confusion Matrix Plot\ndef plot_confusion_matrix(y_true, y_pred, class_names, model_name):\n    \"\"\"Plot confusion matrix\"\"\"\n    cm = confusion_matrix(y_true, y_pred)\n    \n    plt.figure(figsize=(8, 6))\n    plt.style.use('default')  # Use default style for confusion matrix\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=class_names, yticklabels=class_names)\n    plt.title(f'Confusion Matrix - {model_name}')\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.tight_layout()\n    plt.show()\n    \n    return cm\n\n# Precision-Recall Curve\ndef plot_precision_recall_curves(y_true_onehot, y_scores, class_names, model_name):\n    \"\"\"Plot precision-recall curves for all classes\"\"\"\n    plt.figure(figsize=(12, 8))\n    plt.style.use('default')\n    \n    colors = ['blue', 'red', 'green', 'orange']\n    \n    for i in range(len(class_names)):\n        precision, recall, _ = precision_recall_curve(y_true_onehot[:, i], y_scores[:, i])\n        ap_score = average_precision_score(y_true_onehot[:, i], y_scores[:, i])\n        \n        plt.subplot(2, 2, i+1)\n        plt.plot(recall, precision, color=colors[i], linewidth=2)\n        plt.fill_between(recall, precision, alpha=0.3, color=colors[i])\n        plt.xlabel('Recall')\n        plt.ylabel('Precision')\n        plt.title(f'{class_names[i]} (AP: {ap_score:.3f})')\n        plt.grid(True, alpha=0.3)\n    \n    plt.suptitle(f'Precision-Recall Curves - {model_name}', fontsize=16)\n    plt.tight_layout()\n    plt.show()\n    \n    # Calculate mean AP\n    mean_ap = np.mean([average_precision_score(y_true_onehot[:, i], y_scores[:, i]) \n                      for i in range(len(class_names))])\n    \n    return mean_ap\n\n# Create and train models\nmodels_to_compare = {\n    'VGG16':create_VGG(num_classes),\n    'ViT Small': create_vit_small(num_classes),\n    'MobileNet-V1': create_mobilenet_v1(num_classes),\n    'MobileNet-V2': create_mobilenet_v2(num_classes)\n}\n\n# Store results\nresults = {}\nhistories = {}\nconfusion_matrices = {}\ninference_times = {}\n\n# Train each model\nfor model_name, model in models_to_compare.items():\n    print(f\"Model: {model_name}\")\n    \n    # Build the model using a real batch from train_gen if not built\n    if not model.built:\n        # Get one batch of real images from train_gen\n        x_batch, y_batch = next(iter(train_gen))\n        _ = model(x_batch)  # Build the model by calling it on real data\n    \n    print(f\"Parameters: {model.count_params():,}\")\n    \n    # Train model\n    trained_model, history = compile_and_train_model(\n        model, model_name, train_gen, valid_gen, epochs=25\n    )\n    \n    # Evaluate on test set\n    test_loss, test_acc, test_top2_acc = trained_model.evaluate(test_gen, verbose=0)\n    \n    # Get predictions for confusion matrix and PR curves\n    test_gen.reset()  # Reset generator\n    y_pred_probs = trained_model.predict(test_gen, verbose=0)\n    y_pred_classes = np.argmax(y_pred_probs, axis=1)\n    \n    # Get true labels\n    y_true = test_gen.classes\n    y_true_onehot = tf.keras.utils.to_categorical(y_true, num_classes)\n    \n    # Measure inference time\n    test_gen.reset()\n    avg_batch_time, avg_image_time = measure_inference_time(trained_model, test_gen)\n    inference_times[model_name] = {\n        'batch_time': avg_batch_time,\n        'image_time': avg_image_time\n    }\n    \n    # Plot confusion matrix\n    cm = plot_confusion_matrix(y_true, y_pred_classes, class_names, model_name)\n    confusion_matrices[model_name] = cm\n    \n    # Plot precision-recall curves\n    mean_ap = plot_precision_recall_curves(y_true_onehot, y_pred_probs, class_names, model_name)\n    \n    # Calculate additional metrics\n    class_report = classification_report(y_true, y_pred_classes, \n                                       target_names=class_names, output_dict=True)\n    \n    results[model_name] = {\n        'test_accuracy': test_acc,\n        'test_top2_accuracy': test_top2_acc,\n        'test_loss': test_loss,\n        'parameters': model.count_params(),\n        'best_val_accuracy': max(history.history['val_accuracy']),\n        'mean_ap': mean_ap,\n        'precision_macro': class_report['macro avg']['precision'],\n        'recall_macro': class_report['macro avg']['recall'],\n        'f1_macro': class_report['macro avg']['f1-score'],\n        'inference_time_per_image': avg_image_time,\n        'inference_time_per_batch': avg_batch_time\n    }\n    \n    histories[model_name] = history\n    \n    print(f\"Test Accuracy: {test_acc:.4f}\")\n    print(f\"Test Top-2 Accuracy: {test_top2_acc:.4f}\")\n    print(f\"Mean AP: {mean_ap:.4f}\")\n    print(f\"Inference time per image: {avg_image_time*1000:.2f} ms\")\n    print(f\"Best Validation Accuracy: {max(history.history['val_accuracy']):.4f}\")\n\n# Plot combined clean training histories\nprint(f\"\\n{'='*60}\")\nprint(\"COMBINED TRAINING HISTORIES VISUALIZATION\")\nprint(f\"{'='*60}\")\nplot_combined_clean_histories(histories)\n\n# Enhanced visualization function for comprehensive results\ndef plot_comprehensive_results(results, histories, inference_times):\n    # Create comprehensive comparison plots\n    fig, axes = plt.subplots(3, 3, figsize=(20, 18))\n    plt.style.use('default')  # Use default style for comprehensive plots\n    \n    models = list(results.keys())\n    colors = plt.cm.Set3(np.linspace(0, 1, len(models)))\n    \n    # Test Accuracy Comparison\n    test_accs = [results[model]['test_accuracy'] for model in models]\n    bars1 = axes[0, 0].bar(models, test_accs, color=colors)\n    axes[0, 0].set_title('Test Accuracy Comparison', fontsize=14, fontweight='bold')\n    axes[0, 0].set_ylabel('Accuracy')\n    axes[0, 0].set_ylim(0, 1)\n    axes[0, 0].tick_params(axis='x', rotation=45)\n    for i, v in enumerate(test_accs):\n        axes[0, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n    \n    # Parameters vs Accuracy\n    params = [results[model]['parameters'] / 1e6 for model in models]  # in millions\n    scatter = axes[0, 1].scatter(params, test_accs, s=100, c=colors, alpha=0.7)\n    axes[0, 1].set_title('Parameters vs Test Accuracy', fontsize=14, fontweight='bold')\n    axes[0, 1].set_xlabel('Parameters (Millions)')\n    axes[0, 1].set_ylabel('Test Accuracy')\n    for i, model in enumerate(models):\n        axes[0, 1].annotate(model, (params[i], test_accs[i]), \n                           xytext=(5, 5), textcoords='offset points', fontsize=9)\n    \n    # Inference Time Comparison\n    inf_times = [results[model]['inference_time_per_image'] * 1000 for model in models]  # ms\n    bars2 = axes[0, 2].bar(models, inf_times, color=colors)\n    axes[0, 2].set_title('Inference Time per Image', fontsize=14, fontweight='bold')\n    axes[0, 2].set_ylabel('Time (ms)')\n    axes[0, 2].tick_params(axis='x', rotation=45)\n    for i, v in enumerate(inf_times):\n        axes[0, 2].text(i, v + max(inf_times)*0.02, f'{v:.1f}', ha='center', va='bottom')\n    \n    # F1-Score Comparison\n    f1_scores = [results[model]['f1_macro'] for model in models]\n    bars3 = axes[1, 0].bar(models, f1_scores, color=colors)\n    axes[1, 0].set_title('F1-Score (Macro Average)', fontsize=14, fontweight='bold')\n    axes[1, 0].set_ylabel('F1-Score')\n    axes[1, 0].tick_params(axis='x', rotation=45)\n    for i, v in enumerate(f1_scores):\n        axes[1, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n    \n    # Mean Average Precision\n    mean_aps = [results[model]['mean_ap'] for model in models]\n    bars4 = axes[1, 1].bar(models, mean_aps, color=colors)\n    axes[1, 1].set_title('Mean Average Precision', fontsize=14, fontweight='bold')\n    axes[1, 1].set_ylabel('mAP')\n    axes[1, 1].tick_params(axis='x', rotation=45)\n    for i, v in enumerate(mean_aps):\n        axes[1, 1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n    \n    # Efficiency Score (Accuracy / Parameters)\n    efficiency = [results[model]['test_accuracy'] / (results[model]['parameters'] / 1e6) for model in models]\n    bars5 = axes[1, 2].bar(models, efficiency, color=colors)\n    axes[1, 2].set_title('Efficiency Score (Acc/Params)', fontsize=14, fontweight='bold')\n    axes[1, 2].set_ylabel('Efficiency Score')\n    axes[1, 2].tick_params(axis='x', rotation=45)\n    for i, v in enumerate(efficiency):\n        axes[1, 2].text(i, v + max(efficiency)*0.02, f'{v:.3f}', ha='center', va='bottom')\n    \n    # Training History - Best Validation Accuracy per Model\n    best_val_accs = [max(histories[model].history['val_accuracy']) for model in models]\n    bars6 = axes[2, 0].bar(models, best_val_accs, color=colors)\n    axes[2, 0].set_title('Best Validation Accuracy', fontsize=14, fontweight='bold')\n    axes[2, 0].set_ylabel('Best Val Accuracy')\n    axes[2, 0].tick_params(axis='x', rotation=45)\n    axes[2, 0].set_ylim(0, 1)\n    for i, v in enumerate(best_val_accs):\n        axes[2, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n    \n    # Convergence Analysis (Epochs to Best Validation)\n    epochs_to_best = [np.argmax(histories[model].history['val_accuracy']) + 1 for model in models]\n    bars7 = axes[2, 1].bar(models, epochs_to_best, color=colors)\n    axes[2, 1].set_title('Epochs to Best Validation Accuracy', fontsize=14, fontweight='bold')\n    axes[2, 1].set_ylabel('Epochs')\n    axes[2, 1].tick_params(axis='x', rotation=45)\n    for i, v in enumerate(epochs_to_best):\n        axes[2, 1].text(i, v + max(epochs_to_best)*0.02, f'{v}', ha='center', va='bottom')\n    \n    # Speed vs Accuracy Trade-off\n    axes[2, 2].scatter(inf_times, test_accs, s=100, c=colors, alpha=0.7)\n    axes[2, 2].set_title('Speed vs Accuracy Trade-off', fontsize=14, fontweight='bold')\n    axes[2, 2].set_xlabel('Inference Time (ms)')\n    axes[2, 2].set_ylabel('Test Accuracy')\n    for i, model in enumerate(models):\n        axes[2, 2].annotate(model, (inf_times[i], test_accs[i]), \n                           xytext=(5, 5), textcoords='offset points', fontsize=9)\n    \n    plt.tight_layout()\n    plt.show()\n\n# Print detailed results\nprint(\"\\n\" + \"=\"*100)\nprint(\"COMPREHENSIVE RESULTS COMPARISON\")\nprint(\"=\"*100)\n\nresults_df = pd.DataFrame(results).T\nresults_df = results_df.sort_values('test_accuracy', ascending=False)\n\nprint(f\"{'Model':<15} {'Test Acc':<10} {'mAP':<8} {'F1':<8} {'Params(M)':<10} {'Time(ms)':<10} {'Efficiency':<10}\")\nprint(\"-\" * 100)\n\nfor model_name, row in results_df.iterrows():\n    efficiency = row['test_accuracy'] / (row['parameters'] / 1e6)\n    print(f\"{model_name:<15} \"\n          f\"{row['test_accuracy']:<10.4f} \"\n          f\"{row['mean_ap']:<8.3f} \"\n          f\"{row['f1_macro']:<8.3f} \"\n          f\"{row['parameters']/1e6:<10.2f} \"\n          f\"{row['inference_time_per_image']*1000:<10.1f} \"\n          f\"{efficiency:<10.3f}\")\n\nprint(\"\\n\" + \"=\"*100)\nprint(\"DETAILED ANALYSIS:\")\nprint(\"=\"*100)\n\nbest_model = results_df.index[0]\nprint(f\" Best Overall Model: {best_model}\")\nprint(f\"   - Test Accuracy: {results_df.loc[best_model, 'test_accuracy']:.4f}\")\nprint(f\"   - Mean AP: {results_df.loc[best_model, 'mean_ap']:.4f}\")\nprint(f\"   - Parameters: {results_df.loc[best_model, 'parameters']/1e6:.2f}M\")\n\n# Efficiency analysis\nefficiency_scores = results_df['test_accuracy'] / (results_df['parameters'] / 1e6)\nmost_efficient = efficiency_scores.idxmax()\nprint(f\"\\n Most Efficient Model: {most_efficient}\")\nprint(f\"   - Efficiency Score: {efficiency_scores[most_efficient]:.4f}\")\nprint(f\"   - Test Accuracy: {results_df.loc[most_efficient, 'test_accuracy']:.4f}\")\n\n# Speed analysis\nfastest_model = results_df['inference_time_per_image'].idxmin()\nprint(f\"\\n Fastest Model: {fastest_model}\")\nprint(f\"   - Inference Time: {results_df.loc[fastest_model, 'inference_time_per_image']*1000:.1f} ms\")\nprint(f\"   - Test Accuracy: {results_df.loc[fastest_model, 'test_accuracy']:.4f}\")\n\n# Plot comprehensive results\nplot_comprehensive_results(results, histories, inference_times)\n\n# Create training summary for all models\ndef create_training_summary(histories, results):\n    \"\"\"Create a summary table of training characteristics\"\"\"\n    training_data = []\n    \n    for model_name, history in histories.items():\n        val_acc = history.history['val_accuracy']\n        val_loss = history.history['val_loss']\n        train_acc = history.history['accuracy']\n        \n        # Calculate training metrics\n        best_epoch_acc = np.argmax(val_acc) + 1\n        best_epoch_loss = np.argmin(val_loss) + 1\n        best_val_acc = max(val_acc)\n        best_val_loss = min(val_loss)\n        final_overfitting = train_acc[-1] - val_acc[-1]\n        epochs_trained = len(val_acc)\n        \n        # Learning stability (std dev of last 5 epochs)\n        if len(val_acc) >= 5:\n            stability = np.std(val_acc[-5:])\n        else:\n            stability = np.std(val_acc)\n        \n        training_data.append({\n            'Model': model_name,\n            'Best Val Acc': f\"{best_val_acc:.4f}\",\n            'Best Epoch (Acc)': best_epoch_acc,\n            'Best Epoch (Loss)': best_epoch_loss,\n            'Final Overfitting': f\"{final_overfitting:.4f}\",\n            'Epochs Trained': epochs_trained,\n            'Stability (σ)': f\"{stability:.4f}\",\n            'Test Accuracy': f\"{results[model_name]['test_accuracy']:.4f}\"\n        })\n    \n    training_df = pd.DataFrame(training_data)\n    training_df = training_df.sort_values('Best Val Acc', ascending=False)\n    \n    print(\"\\n\" + \"=\"*110)\n    print(\"TRAINING CHARACTERISTICS SUMMARY\")\n    print(\"=\"*110)\n    print(training_df.to_string(index=False))\n    \n    return training_df\n\n# Create training summary\ntraining_summary = create_training_summary(histories, results)\n\n# Create final comprehensive summary table\ndef create_final_summary_table(results):\n    \"\"\"Create final comprehensive summary table\"\"\"\n    summary_data = []\n    \n    for model_name, metrics in results.items():\n        summary_data.append({\n            'Model': model_name,\n            'Test Accuracy': f\"{metrics['test_accuracy']:.4f}\",\n            'Top-2 Accuracy': f\"{metrics['test_top2_accuracy']:.4f}\",\n            'mAP': f\"{metrics['mean_ap']:.4f}\",\n            'F1-Score': f\"{metrics['f1_macro']:.4f}\",\n            'Precision': f\"{metrics['precision_macro']:.4f}\",\n            'Recall': f\"{metrics['recall_macro']:.4f}\",\n            'Parameters (M)': f\"{metrics['parameters']/1e6:.2f}\",\n            'Inference (ms)': f\"{metrics['inference_time_per_image']*1000:.1f}\",\n            'FPS': f\"{1/(metrics['inference_time_per_image']):.1f}\",\n            'Efficiency Score': f\"{metrics['test_accuracy']/(metrics['parameters']/1e6):.3f}\"\n        })\n    \n    summary_df = pd.DataFrame(summary_data)\n    summary_df = summary_df.sort_values('Test Accuracy', ascending=False)\n    \n    return summary_df\n\nfinal_summary = create_final_summary_table(results)\n\nprint(\"\\n\" + \"=\"*140)\nprint(\"FINAL COMPREHENSIVE SUMMARY TABLE\")\nprint(\"=\"*140)\nprint(final_summary.to_string(index=False))\n\n# Save all results\nfinal_summary.to_csv('comprehensive_model_comparison.csv', index=False)\ntraining_summary.to_csv('training_characteristics_summary.csv', index=False)\nresults_df.to_csv('detailed_model_results.csv')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-14T09:16:24.327484Z","iopub.execute_input":"2025-09-14T09:16:24.327691Z","execution_failed":"2025-09-14T09:17:00.003Z"}},"outputs":[{"name":"stderr","text":"2025-09-14 09:16:25.901551: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757841386.095504      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757841386.150243      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Class distribution:\nlabels\ndiabetic_retinopathy    1098\nnormal                  1074\ncataract                1038\nglaucoma                1007\nName: count, dtype: int64\nNumber of unique classes: 4\nTrain samples: 3373\nValid samples: 506\nTest samples: 338\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"best_overall = results_df.index[0]\nefficiency_scores = results_df['test_accuracy'] / (results_df['parameters'] / 1e6)\nmost_efficient = efficiency_scores.idxmax()\nfastest = results_df['inference_time_per_image'].idxmin()\n\nprint(f\" For MAXIMUM ACCURACY: {best_overall}\")\nprint(f\"    Test Accuracy: {results_df.loc[best_overall, 'test_accuracy']:.4f}\")\nprint(f\"    Parameters: {results_df.loc[best_overall, 'parameters']/1e6:.2f}M\")\nprint(f\"    Use when: Highest performance is critical, resources are not limited\")\n\nprint(f\"\\n For BEST EFFICIENCY: {most_efficient}\")\nprint(f\"   → Efficiency Score: {efficiency_scores[most_efficient]:.4f}\")\nprint(f\"   → Test Accuracy: {results_df.loc[most_efficient, 'test_accuracy']:.4f}\")\nprint(f\"   → Use when: Balance between performance and model size matters\")\n\nprint(f\"\\n🚀 For FASTEST INFERENCE: {fastest}\")\nprint(f\"   → Inference Time: {results_df.loc[fastest, 'inference_time_per_image']*1000:.1f} ms\")\nprint(f\"   → Test Accuracy: {results_df.loc[fastest, 'test_accuracy']:.4f}\")\nprint(f\"   → Use when: Real-time inference is required\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}